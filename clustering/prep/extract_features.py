#!/usr/bin/env python
# -*- coding: utf-8 -*-
import json
import argparse
import sys
import operator
import M2Crypto
import hashlib
from datetime import datetime
import time as mod_time
import urllib2
import csv
from netaddr import IPNetwork, IPAddress
sys.path.insert(1, '../lib')
import x509
import parse_tls_fprints


SINKHOLE_URL = "https://raw.githubusercontent.com/brakmic/"\
               "Sinkholes/master/Sinkholes_List.csv"


def pprint_dict(dic):
    '''Pretty prints a dictionary'''
    import pprint
    pp = pprint.PrettyPrinter(indent=4)
    pp.pprint(dic)


def md5_data(data):
    '''Calculates the MD5 hash of the data provided
       Args:
         -Data[string|list]
       Returns:
         -Returns the calculated hash
    '''
    m = hashlib.md5()
    if isinstance(data, list):
        m.update(''.join(data))
    else:
        m.update(data)
    data_hash = m.hexdigest()
    return data_hash


def parse_avclass_results(avc_file):
    avc_fams = {}
    with open(avc_file, 'r') as fr:
        for pos, line in enumerate(fr):
            fhash, fam, pup = line.strip('\n').split('\t')
            if 'SINGLETON' in fam:
                continue
            avc_fams[fhash] = fam
    return avc_fams


def get_sinkhole_list(url):
    sinkholed_ranges = {}
    filedata = urllib2.urlopen(url)
    csvfile = csv.DictReader(filedata, delimiter=',')
    # Expected fields: 'Organization', 'IP Range', 'Whois', 'Notes'
    for row in csvfile:
        if '-' in row['IP Range']:
            # Some ranges are reported in a stupid way e.g., 131.253.18.11-12
            last = int(row['IP Range'].split('-')[1])
            first = int(row['IP Range'].split('-')[0].split('.')[-1])
            for x in range(first, last):
                base = [str(z) for z in row['IP Range'].split('.')[:3]]
                base.append(str(x))
                new_ip = '.'.join(base)
                sinkholed_ranges[IPNetwork(new_ip)] = row['Organization']
            continue
        sinkholed_ranges[IPNetwork(row['IP Range'])] = row['Organization']
    return sinkholed_ranges


def parse_vt_info(vt_file):
    vt_info = {}
    with open(vt_file, 'r') as fr:
        for pos, line in enumerate(fr):
            # if pos and pos % 1000 == 0:
            #     break
            rep = json.loads(line.strip('\n'))
            try:
                score = rep['positives']
                sseen = rep['scan_date']
            except KeyError:
                continue
            else:
                if sseen:
                    sseen_date = datetime.strptime(sseen, '%Y-%m-%d %H:%M:%S')
            try:
                old_entry = vt_info[rep['resource']]
            except KeyError:
                # Add entry
                vt_info[rep['resource']] = {'score': score,
                                            'scan_date': sseen_date}
            else:
                if not old_entry['scan_date'] or\
                  sseen_date > old_entry['scan_date']:
                    # Update score and date
                    vt_info[rep['resource']]['score'] = score
                    vt_info[rep['resource']]['scan_date'] = sseen_date
    return vt_info


def get_resumed_conns(ssldmlog):
    resumed_from = {}
    server_session_ids = {}
    server_session_tickets = {}
    fake_resumed_conns = []
    # Do a pass to store the Session IDs/Tickets provided by the servers
    for en in ssldmlog:
        # Fill the cache
        if not en['resumed']:
            # Fill the cache
            if en['s_session_id']:
                server_session_ids[en['s_session_id']] = {
                  'init_uid': en['conn_uid'],
                  's_leaf_cert_validity':  en['s_leaf_cert_validity'],
                  's_leaf_cert_num_SAN':  en['s_leaf_cert_num_SAN'],
                  's_leaf_cert_self_signed': en['s_leaf_cert_self_signed'],
                  's_num_certs': en['s_num_certs'],
                  's_leaf_cert_validation_status':\
                                 en['s_leaf_cert_validation_status'],
                  's_extensions': en['s_extensions']}
            if en['s_session_ticket']:
                server_session_tickets[en['s_session_ticket']] = {
                  'init_uid': en['conn_uid'],
                  's_leaf_cert_validity':  en['s_leaf_cert_validity'],
                  's_leaf_cert_num_SAN':  en['s_leaf_cert_num_SAN'],
                  's_leaf_cert_self_signed': en['s_leaf_cert_self_signed'],
                  's_num_certs': en['s_num_certs'],
                  's_leaf_cert_validation_status':\
                                 en['s_leaf_cert_validation_status'],
                  's_extensions': en['s_extensions']}
    for en in ssldmlog:
        # print en.keys()
        if en['resumed']:
            # Map the resumed connection with the initial one
            if en['c_session_id']:
                try:
                    resumed_from[en['conn_uid']] =\
                            server_session_ids[en['c_session_id']]
                except KeyError:
                    fake_resumed_conns.append(en['conn_uid'])
            else:
                try:
                    resumed_from[en['conn_uid']] =\
                            server_session_tickets[en['c_session_ticket']]
                except KeyError:
                    fake_resumed_conns.append(en['conn_uid'])

    return resumed_from, fake_resumed_conns


def extract_cert_features(certs_log, certs_dir):
    ''' '''
    def parse_cert(certs_dir, der_hash, ctype='s'):
         certf = '{}{}.pem'.format(certs_dir, der_hash)
         cert_obj = M2Crypto.X509.load_cert(certf)
         try:
             cert_fields = x509.extract_cert_fields(cert_obj, certf, ctype)
         except:
             raise
         return cert_fields
    certs_info = {}
    server_certs = {}
    client_certs = {}
    for en in certs_log:
        if en['cert_idx'] == "S0":
            cert_fields = parse_cert(certs_dir, en['DER_hash'])
            server_certs[en['conn_uid']] = cert_fields
            # certs_info[en['conn_uid']] = {'s_leaf_cert': cert_fields,
            #                               'c_leaf_cert': None}
        if en['cert_idx'] == "C0":
            cert_fields = parse_cert(certs_dir, en['DER_hash'], ctype='c')
            # certs_info[en['conn_uid']]['c_leaf_cert'] = cert_fields
            client_certs[en['conn_uid']] = cert_fields
    #
    for cuid, cinfo in server_certs.items():
        try:
            ccert = client_certs[cuid]
        except KeyError:
            ccert = {}
        certs_info[cuid] = {'s_leaf_cert': cinfo, 'c_leaf_cert': ccert}
    return certs_info


def main(args):
    """ """
    # Parse TLS finterprins
    tls_fprints = {}
    if args.fprints:
        tls_fprint_db = parse_tls_fprints.TLSFingerprintDB(args.fprints)
        tls_fprints = tls_fprint_db.get_contents()
        sys.stderr.write('[-] Parsed known TLS fingerprints\n')

    # Parse AVClass results
    avc_fams = {}
    if args.avc:
        avc_fams = parse_avclass_results(args.avc)
        sys.stderr.write('[-] Processed AVClass families\n')

    # Get VT scores from VT reports
    vt_info = {}
    if args.vt:
        vt_info = parse_vt_info(args.vt)
        sys.stderr.write('[-] Processed VT scores\n')

    # Get the Sinkholed IPs
    sinkholed_ranges = get_sinkhole_list(SINKHOLE_URL)
    sys.stderr.write('[-] Got list of sinkholed IPs\n')

    print_headers = True
    with open(args.logs) as fr:
        for pos, en in enumerate(fr):
            # if pos and pos % 1000 == 0:
            #     break
            entry = json.loads(en)
            sha2 = entry[0].replace('.pcap', '')
            pcap_md5 = entry[1]
            if not entry[2]:
                sys.stderr.write('[-] Error: No Bro logs for pcap: {}\n'.\
                                 format(entry[0]))
                continue

            # Get AVClass family (if we have it)
            try:
                family = avc_fams[sha2]
            except KeyError:
                family = '-'

            # Get the VT score
            try:
                vt_score = str(vt_info[sha2]['score'])
            except KeyError:
                vt_score = '-'

            if 'ssl_dm.log' not in entry[2]:
                sys.stderr.write('[-] Error: No ssl_dm log for pcap: {}\n'.\
                                 format(entry[0]))
                continue
            sys.stderr.write('[-] Processing pcap: {}\n'.format(entry[0]))

            # Get the mapping from a resumed connection to the initial one
            # This way you can use the initial conn_uid to extract any desired
            # features that exist only in the full handshake
            resumed_from, fake_resumed_conns =\
                    get_resumed_conns(entry[2]['ssl_dm.log'])

            if fake_resumed_conns:
                sys.stderr.write('\t[-] Fake resumed connections ({})'\
                                 ' in pcap: {}\n'.\
                                 format(','.join(fake_resumed_conns),
                                        entry[0]))

            # Get certificate info
            certs_info = {}
            if 'ssl_certs.log' in entry[2]:
                certs_info = extract_cert_features(entry[2]['ssl_certs.log'],
                                                   args.certs)

            # Parse Gibran's fields
            if print_headers:
                headers = sorted(entry[2]['ssl_dm.log'][0].keys())
                headers.insert(0, 'sha2')
                headers.insert(1, 'pcap_md5')
                headers.insert(2, 'vt_score')
                headers.insert(3, 'avclass_family')
                headers.insert(4, 'c_tls_fingerprint')
                headers.insert(5, 'c_tls_fingerprint_md5')
                headers.insert(6, 'c_tls_fingerprint_label')
                headers.insert(7, 'c_fake_resumption')
                headers.insert(8, 's_ip_sinkholed')
                headers.insert(9, 's_ip_sinkholed_by')
                headers.insert(10, 'md5_conn_id')
                # certs_info is empty if the pcaps contain TLSv1.3 traffic only
                if certs_info:
                    s_cert_fields =\
                        certs_info.items()[0][1]['s_leaf_cert'].keys()
                else:
                    s_cert_fields = []
                headers = headers + sorted(s_cert_fields)
                c_cert_fields = [x.replace('s_','c_',1) for x in s_cert_fields]
                headers = headers + sorted(c_cert_fields)
                sys.stdout.write('{}\n'.format('\t'.join(headers)))
                print_headers = False
            conns_without_cert = set()
            for pos, en in enumerate(entry[2]['ssl_dm.log']):
                if en['resumed'] and en['conn_uid'] not in fake_resumed_conns:
                    # Get cert features from the initial connections
                    res_conn = resumed_from[en['conn_uid']]
                    try:
                        cert_info = certs_info[res_conn['init_uid']]
                    except KeyError:
                        # When working with bro logs instead of pcaps, it can
                        # happen that a valid conn doesn't appear in ssl_certs
                        # (also in case there are only TLSv3 traffic)
                        conns_without_cert.add(res_conn['init_uid'])
                        cert_info = {'s_leaf_cert': {}, 'c_leaf_cert': {}}
                        for cf in s_cert_fields:
                            cert_info['s_leaf_cert'][cf] = '-'
#                    cert_info =\
#                        certs_info[resumed_from[en['conn_uid']]['init_uid']]
                    # Fill fields from the initial connection
                    en['s_leaf_cert_validity'] =\
                        resumed_from[en['conn_uid']]['s_leaf_cert_validity']
                    en['s_leaf_cert_num_SAN'] =\
                       resumed_from[en['conn_uid']]['s_leaf_cert_num_SAN']
                    en['s_leaf_cert_validation_status'] =\
                       resumed_from[en['conn_uid']]\
                                   ['s_leaf_cert_validation_status']
                    en['s_leaf_cert_self_signed'] =\
                        resumed_from[en['conn_uid']]['s_leaf_cert_self_signed']
                    en['s_num_certs'] =\
                        resumed_from[en['conn_uid']]['s_num_certs']
                    ####################################################
                    # !! WARNING: Overwriting s_extensions on resumption
                    ####################################################
                    en['s_extensions'] =\
                        resumed_from[en['conn_uid']]['s_extensions']
                    ####################################################
                    # fields = [str(v) for v in en.values()]
                else:
                    try:
                        cert_info = certs_info[en['conn_uid']]
                    except KeyError:
                        #There are these fake resumed conns that the server
                        #does not provide any certificate
                        cert_info = {'s_leaf_cert': {}, 'c_leaf_cert': {}}
                        for cf in s_cert_fields:
                            cert_info['s_leaf_cert'][cf] = '-'
                # If not client cert exists fill the c_leaf_cert features
                # with dashes
                if not cert_info['c_leaf_cert']:
                    for cf in c_cert_fields:
                        cert_info['c_leaf_cert'][cf] = '-'

                sorted_fields = sorted(en.items(),
                                       key=operator.itemgetter(0))
                fields = [str(v) for (k,v) in sorted_fields]
                # Get TLS fingerprint
                tls_fp = '{};{};{};{}'.format(en['c_ciphers'],
                                              en['c_extensions'],
                                              en['c_curves'],
                                              en['c_point_formats']).\
                                                      replace('-','')
                tls_fp_md5 = md5_data(tls_fp)
                try:
                    tls_fp_label = tls_fprints[tls_fp_md5]['desc']
                except KeyError:
                    tls_fp_label = '-'
                # Check if is fake resumed
                fake_resumption = 'False'
                if en['conn_uid'] in fake_resumed_conns:
                    fake_resumption = 'True'
                # Check if DST_IP is sinkholed
                dst_ip_sinkholed = "False"
                dst_ip_sinkholed_by = "-"
                for ip_range, org in sinkholed_ranges.items():
                    if IPAddress(en['s_dst_ip']) in ip_range:
                        dst_ip_sinkholed = "True"
                        dst_ip_sinkholed_by = "{}()".format(org, str(ip_range))
                # Calculate md5 connection identifier
                port_proto = en['c_src_port'].split('/')
                src_port, src_proto = port_proto[0], port_proto[1]
                port_proto = en['s_dst_port'].split('/')
                dst_port, dst_proto = port_proto[0], port_proto[1]
                ts = datetime.strptime(en['start_time'], '%Y-%m-%d %H:%M:%S:%f')
                # Python 3
                #t = datetime.timestamp(ts)
                # Python 2.x don't have timestamp(), calculating timestamp
                #t = mod_time.mktime(ts.timetuple()) + ts.microsecond / 1e6
                #mci_str = '{},{},{},{},{},{}'.format(
                mci_str = '{},{},{},{},{}'.format(
                            en['c_src_ip'], src_port,
                            en['s_dst_ip'], dst_port,
                            src_proto)
                            #src_proto, t)
                md5_conn_id = md5_data(mci_str)
                # Add general info
                fields.insert(0, sha2)
                fields.insert(1, pcap_md5)
                fields.insert(2, vt_score)
                fields.insert(3, family)
                fields.insert(4, tls_fp)
                fields.insert(5, tls_fp_md5)
                fields.insert(6, tls_fp_label)
                fields.insert(7, fake_resumption)
                fields.insert(8, dst_ip_sinkholed)
                fields.insert(9, dst_ip_sinkholed_by)
                fields.insert(10, md5_conn_id)
                sorted_s_cert_info = sorted(cert_info['s_leaf_cert'].items(),
                                          key=operator.itemgetter(0))
                fields = fields + [str(v) for (k,v) in sorted_s_cert_info]
                sorted_c_cert_info = sorted(cert_info['c_leaf_cert'].items(),
                                          key=operator.itemgetter(0))
                fields = fields + [str(v) for (k,v) in sorted_c_cert_info]
                sys.stdout.write('{}\n'.format('\t'.join(fields)))
            sys.stderr.write('\t[-] Conns without an entry in ssl_certs: {}\n'\
                    .format(','.join(conns_without_cert)))


if __name__ == '__main__':
    # Process parameters
    argparser = argparse.ArgumentParser(prog='extract_features',
                      description="Extract features from Bro logs")
    argparser.add_argument('--logs', help='file with logs', required=True)
    argparser.add_argument('--certs', help='Certs directory', required=True)
    argparser.add_argument('--avc', help='AVClass labels')
    argparser.add_argument('--vt', help='VT jsons')
    argparser.add_argument('--fprints', help='Known TLS fingerprints file')
    args = argparser.parse_args()
    if args.certs[-1] != '/': args.certs += '/'
    main(args)
