#!/usr/bin/env python
# coding: utf-8

import os
import sys
import csv
import json
import optparse
from collections import Counter, defaultdict
path = os.path.dirname(os.path.abspath(__file__))
libpath = os.path.join(path, '../lib/')
sys.path.insert(0, libpath)
import grouping

def parse_groups_dataset(sni_path, dataset):
    g_tmp = defaultdict(defaultdict)
    groups = defaultdict(defaultdict)
    empty = set()
    classes = {}
    # Load groups by sni (esld)
    with open(sni_path) as pf:
        for line in pf:
            pline = line.strip().split(',')
            cid = pline[0]
            label = int(pline[1])
            g_tmp[cid][label] = '0'
    # Load the dataset
    with open(dataset) as csv_file:
        csv_dict = csv.DictReader(csv_file, delimiter='\t')
        for elem in csv_dict:
            # Take groups-clustered connections only
            eid = '{}:{}'.format(elem['sha2'], elem['conn_uid'])
            if eid in g_tmp:
                label = next(iter(g_tmp[eid]))
                groups[label][eid] = elem['s_leaf_cert_der_hash']
                classes[eid] = elem['avclass_family']
                if elem['enc_data_size'] == '0':
                    empty.add(eid)
    return groups, classes, empty

def compare_certs(d1, d2):
    certs_c1 = set(d1.values())
    certs_c2 = set(d2.values())
    if options.aggressive:
        return certs_c1.intersection(certs_c2)
    else:
        return certs_c1 == certs_c2

def search_group(c, e, groups):
    for x, xset in groups.items():
        if e in xset:
            return x
    return c

def merge_clusters(merge_these, groups):
    for c, cset in merge_these.items():
        items = groups.pop(c)
        for e in cset:
            items.update(groups.pop(e))
        groups[c] = items
    return groups

#def output_as_json(clusters, classes):
#    res = []
#    for label, cids in sorted(clusters.items()):
#        idclasses = Counter(classes[i] for i in cids).most_common()
#        current = {
#            'label': int(label),
#            'ids': cids,
#            'avclass': idclasses,
#            'size': len(cids),
#        }
#        res.append(current)
#    return res

def main(options, args):
    # Parse groups by SNI and original dataset
    groups, classes, empty = parse_groups_dataset(options.groups, args[0])

    if options.debug:
        print('Pre-processing {} vectors.'.format(len(classes)))

    omit = set([e for e, d in groups.items() if set(d.keys()).issubset(empty)])
    print('OMIT THESE: {}'.format(omit))
    merge_these = defaultdict(set)
    for c, ids in sorted(groups.items()):
        if c in omit:
            continue
        omit.add(c)
#        print('>> Searching intersections with cluster {}'.format(c))
        if options.aggressive:
            g = search_group(c, c, merge_these)
#            print('>> search_group returned {} for {}'.format(g, c))
        tocheck = sorted([x for x in groups if x not in omit])
        for e in tocheck:
            if compare_certs(ids, groups[e]):
                if options.aggressive:
                    gg = search_group(g, e, merge_these)
#                    print('>> search_group returned {} for {}'.format(gg, e))
                    if gg != g:
#                        print('>> Merging groups ({}, {}) because of {}'\
#                                        .format(gg, g, e))
                        # Add g to its own list of clusters
                        merge_these[g].add(g)
                        # Merge elements of g into gg
                        g_list = merge_these.pop(g)
                        merge_these[gg].update(g_list)
                        # If there are more clusters to merge, add them to gg
                        g = gg
                    else:
                        merge_these[g].add(e)
                else:
                    merge_these[c].add(e)
                    omit.add(e)
                if options.debug:
                    print('>> Found same group of certs:')
                    s1 = sorted(set(ids.values()))
                    s2 = sorted(set(groups[e].values()))
                    print('{} <-> {}'.format(s1, s2))

    if options.debug:
        print('>> MERGE_THESE: {}'.format(merge_these))

    groups_merged = merge_clusters(merge_these, groups)

    output_file = 'tls_clustering_grouping_cert.tsv'
    output_json = 'tls_clustering_grouping_cert.json'

    labels = []
    with open(output_file, 'w') as of:
        clusters = defaultdict(list)
        for new_label, (label, ids) in enumerate(groups_merged.items()):
            clusters[new_label] = [id for id in ids]
            for id, chash in ids.items():
                print('{},{},{}'.format(id, new_label, chash), file=of)
                labels.append(new_label)

    with open(output_json, 'w') as oj:
        json_out = grouping.output_as_json(clusters, classes)
        json.dump(json_out, oj)

    if options.debug:
        print('Groups in the most common(20) list:')
        for label, total in Counter(labels).most_common(20):
            print('\t{}:\t{}'.format(label, total))

    if options.debug:
        print('Grouping by server certificate, done.')


if __name__ == '__main__':
    parser = optparse.OptionParser(
            usage="Usage: %prog [options] dataset_filename",
            version="%prog 1.0")
    parser.add_option(
            '-g', '--groups', action='store', dest='groups',
            help='Path to the file containing the groups by SNI')
    parser.add_option(
            '-a', '--aggressive', action='store_true', dest='aggressive',
            help='Merge two groups if at least one cert is present in both',
            default=False)
    parser.add_option(
            '-D', '--debug', action='store_true', dest='debug',
            help='Print debug messages',
            default=False)

    options, args = parser.parse_args()

    if len(args) != 1 or not os.path.isfile(args[0]):
        parser.error("Dataset not found. Aborting...")
    if not os.path.isfile(options.groups):
        parser.error("File with groups by SNI not found. Aborting...")

    main(options, args)
