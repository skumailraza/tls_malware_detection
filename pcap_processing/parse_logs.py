#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
reload(sys)
sys.setdefaultencoding("utf-8")
import os
import glob
import json

sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(
  os.path.abspath(os.path.dirname(__file__))))))
import argparse
sys.path.insert(1, 'lib')
import progress_bar as pb
from brologparse import parse_log


def main(args):
    """ """
    cwd = os.getcwd()

    if not os.path.isdir(args.dcerts):
        os.mkdir(args.dcerts)

    certs_dir = os.path.abspath(args.dcerts)

    # Move to the logs dir
    os.chdir(args.dir)

    # Prepare list of pcap files to be processed
    logs = glob.glob('*.log')
    if not logs:
        sys.stderr.write('[-] Missed bro logs.\n')
        exit(1)

    # Total operations to be done
    total_logs_cnt = len(logs) + 1

    with open(os.path.join(cwd, args.ofile), 'w', 0) as fw:
        first = True
        #TODO: Transform input dir name into hash
        fw.write('["{}", "NOMD5", '.format(args.dir))
        fw.write('{')
        for pos, log in enumerate(logs):
            pb.update_progress_bar(pos, total_logs_cnt)
            # This is a log file used internally by our Bro script; Ignore it
            if log == 'dns_cache.log':
                continue

            # With large files we will only parse these files
            if args.optimize and log != 'ssl_dm.log' and log != 'ssl_certs.log':
                continue

            # When Bro fails our custom logs are created but they are empty
            if not os.path.getsize(log):
                sys.stderr.write('[-] Log is empty: {}\n'.format(log))
                continue

            sys.stderr.write("[+] Parsing log file: {}\n".format(log))

            try:
                # Get all records from this log
                records = parse_log(os.path.abspath(log))

                # Store records for this log in JSON format
                if records:

                    if not first:
                        fw.write(',')

                    fw.write('"' + log + '":[')
                    for n, entry in enumerate(records):
                        if n:
                            fw.write(',')
                        json.dump(entry._asdict(), fw)
                        fw.flush()
                    fw.write(']')
                    first = False

                else:
                    sys.stderr.write('[-] No records for log: {}\n'.format(log))

            except Exception as e:
                sys.stderr.write('\t[!] Error: {}\n'.format(repr(e)))

            fw.flush()

        fw.write('}]\n')
        pb.update_progress_bar(pos, total_logs_cnt - 1)

    # Store certificates in certs directory
    os.system("cp *.pem {}/ 2> /dev/null".format(certs_dir))

    pb.update_progress_bar(pos, total_logs_cnt)

    # Return to current working directory
    os.chdir(cwd)


def validate_config(args):
    if not args.dir:
        sys.stderr.write('[+] Error: Provide the --dir parameter.\n')
        exit(1)
    if args.dir and not os.path.exists(args.dir):
        sys.stderr.write('[+] Error: Directory with bro logs does not exist.\n')
        exit(1)


if __name__ == '__main__':
    # Process parameters
    argparser = argparse.ArgumentParser(prog='parse_bro_logs',
            description='''Parse a dir with bro logs into JSON format''')
    argparser.add_argument('--dir', help='dir with bro logs')
    argparser.add_argument('--ofile', help='file to store the JSON file',
            required=True)
    argparser.add_argument('--dcerts', help='dir to store certificates',
            required=True)
    argparser.add_argument('--optimize', help='Indicate to only store ssl_dm'\
            ' and ssl_certs logs (for very large files)', action='store_true',
            default=False)
    args = argparser.parse_args()
    validate_config(args)
    main(args)
